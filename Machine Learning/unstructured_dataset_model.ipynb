{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc529a9f-7fd9-4bb1-a669-b3e21a70fb9b",
   "metadata": {},
   "source": [
    "# Predicting Unstructured Data Using Convolutional Neural Networks (CNN) and Random Forests (RF)\n",
    "This is a small demonstration of two Machine Learning Models to compare its predictive power in an unstructured dataset (numerical images from the sikit learn library). This Jupyter Notebook is available for download, the code includes the import of the relevant dataset. The models will be resolving the same problem with the same dataset. Data Analysis of the results will be presented in the Looker Studio section. Be mindful of the considerations of the model specified at the end of the Notebook before extrapolating these results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991aa2a1-a57c-444f-84dc-053821fc5e80",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0102e52-52ba-4ee5-b734-5d0ff603d068",
   "metadata": {},
   "source": [
    "We import load_digits from sklearn, the object that contains the digits dataset, as well as all other libraries that are required for this anlaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1c88ad-25e8-45b2-86d4-dc79622a614b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "for i in range(1,17):\n",
    "    plt.subplot(4,4,i)\n",
    "    plt.imshow(digits.images[i,:,:], cmap=plt.get_cmap('gray_r'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8711031-036c-4424-8d96-58732e1f9f50",
   "metadata": {},
   "source": [
    "We transform it into a Pandas DataFrame to utilize it for Random Forests later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "175610b0-99e0-4d79-8d2d-9f8bdc7349e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3        0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       "0        0.0        6.0       13.0       10.0        0.0        0.0   \n",
       "1        0.0        0.0       11.0       16.0       10.0        0.0   \n",
       "2        0.0        0.0        3.0       11.0       16.0        9.0   \n",
       "3        0.0        7.0       13.0       13.0        9.0        0.0   \n",
       "4        0.0        0.0        2.0       16.0        4.0        0.0   \n",
       "\n",
       "   pixel_7_7  target  \n",
       "0        0.0       0  \n",
       "1        0.0       1  \n",
       "2        0.0       2  \n",
       "3        0.0       3  \n",
       "4        0.0       4  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_df = pd.DataFrame(data=digits.data, columns=digits.feature_names)\n",
    "\n",
    "digits_df['target'] = digits.target\n",
    "\n",
    "digits_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2be3a5-9cc5-4ed3-9cf0-67e0f29f43cf",
   "metadata": {},
   "source": [
    "As it is a DataFrame, we can group to see the data distribution of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "414579dd-0f4a-4e2d-992e-6930397d6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = digits_df['target'].value_counts()\n",
    "target_counts_df = target_counts.reset_index()\n",
    "target_counts_df.columns = ['number', 'amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf577a-f02a-4214-aa76-7ab40ed40657",
   "metadata": {},
   "source": [
    "We have an evenly distributed, albeit small, dataset with which to train our supervised learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c8c89a-a1fc-486e-b2cf-7b735a63ff74",
   "metadata": {},
   "source": [
    "# Spliting the data\n",
    "The data will be split into two sub datasets, one for training, one for testing. Proportions will be 80% and 20% respectively. Do note that it is preferable to do feature engineering to save some time before doing the split (except for the validation set which should be kept separated at all times), but since im not doing feature engineering in this small example we will procede with this step right away. Predictions in the test sets will be compared later between the two models. As there is no engineering, there will also not be a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e9a0cf-8735-4611-8208-009bfce772a5",
   "metadata": {},
   "source": [
    "#### Dataframe for Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64b6ee91-75ed-437e-bf58-7afa1186ac20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values in each Dataframe\n",
      "train:  1437\n",
      "test:  360\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(digits_df, test_size=0.2, random_state=42)\n",
    "print('Values in each Dataframe')\n",
    "print('train: ', str(df_train.shape[0]))\n",
    "print('test: ', str(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800099c7-7fb6-400f-aca0-855bc9bca415",
   "metadata": {},
   "source": [
    "#### Dataset for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1394464-75dd-4df4-92cf-cb9d9286fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.df = df\n",
    "        self.pixel_columns = [f'pixel_{i}_{j}' for i in range(8) for j in range(8)]  # 8x8 pixels\n",
    "        self.target_column = 'target'\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = self.df.iloc[idx][self.pixel_columns].values \n",
    "        target = self.df.iloc[idx][self.target_column]  \n",
    "        \n",
    "        image = image.reshape(1, 8, 8) \n",
    "        \n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        target = torch.tensor(target, dtype=torch.long) \n",
    "        \n",
    "        return image, target\n",
    "\n",
    "CNN_train = ImageDataset(df_train)\n",
    "CNN_test = ImageDataset(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5205e491-0641-4dbf-be3e-1af625381fe0",
   "metadata": {},
   "source": [
    "# Definiton and training of the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e518991-7695-4c51-a256-2ea125bc1780",
   "metadata": {},
   "source": [
    "This CNN will have two convolutional layers with max pooling applied to its outputs, and two fully conected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ea6f424-dde5-44a2-851d-859312bbd6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        #Convolutional Layers\n",
    "        super(NetCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        #Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(16 * 2 * 2, 120)  \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with ReLU activation and max pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=2, stride=2)  # Output: (6, 4, 4)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=2, stride=2)  # Output: (16, 2, 2)\n",
    "        \n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        x = x.view(-1, 16 * 2 * 2)  # Flatten: 16 channels * 2x2 feature map size\n",
    "        \n",
    "        # Fully connected layers with ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # Output: 10 classes\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888bcccc-4042-41d9-b3b7-e22f0955f4ba",
   "metadata": {},
   "source": [
    "Training the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a092768-fa5e-434e-8566-b52e32d763c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "device = torch.device('cpu')\n",
    "net = NetCNN()\n",
    "net.to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "#Cross entropy to be used as Loss Function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loader = DataLoader(dataset=CNN_train, batch_size=20, shuffle=True)\n",
    "num_epochs = 20\n",
    "\n",
    "# Defining the forward and backward process\n",
    "for i in range(num_epochs):\n",
    "    for x, y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        loss = criterion(net(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "torch.save(net.state_dict(), \"./cnn20.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93999a91-1d59-45d0-b694-c7ed607382f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      0.82      0.90        28\n",
      "           2       0.89      1.00      0.94        33\n",
      "           3       0.97      1.00      0.99        34\n",
      "           4       0.98      1.00      0.99        46\n",
      "           5       0.98      0.94      0.96        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.94      0.97      0.96        34\n",
      "           8       0.88      0.97      0.92        30\n",
      "           9       0.94      0.85      0.89        40\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.95      0.95       360\n",
      "weighted avg       0.96      0.96      0.95       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmala\\AppData\\Local\\Temp\\ipykernel_12208\\1693141818.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(\"./cnn20.pth\"))\n"
     ]
    }
   ],
   "source": [
    "net = NetCNN()\n",
    "net.load_state_dict(torch.load(\"./cnn20.pth\"))\n",
    "net.to(device)\n",
    "\n",
    "loader_test = DataLoader(dataset=CNN_test, batch_size=10000, shuffle=False)\n",
    "x_test = list(loader_test)[0][0]\n",
    "y_test = list(loader_test)[0][1]\n",
    "\n",
    "x_test = x_test.to(device)\n",
    "\n",
    "pred = net(x_test)\n",
    "\n",
    "pred_y = torch.max(pred.to(\"cpu\"), 1)[1].data.numpy()\n",
    "\n",
    "print(classification_report(y_test, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd50884-4e93-462d-ba62-6fa2d2c0a7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
